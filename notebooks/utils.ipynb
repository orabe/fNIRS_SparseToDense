{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05feb8f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cedalion\n",
    "import cedalion.sigproc.motion_correct as motion_correct\n",
    "import random\n",
    "\n",
    "def create_train_test_files(bids_path, preprocessed_path, test_subjects_list=None, test_subject_percentage=0.2):\n",
    "    \"\"\"\n",
    "    Create train and test files for the dataset.\n",
    "    \"\"\"\n",
    "    participants_df = pd.read_csv(os.path.join(bids_path, \"participants.tsv\"), sep=\"\\t\")\n",
    "\n",
    "    if test_subjects_list is not None:\n",
    "        for test_subject in test_subjects_list:\n",
    "            if test_subject not in participants_df[\"participant_id\"].values:\n",
    "                raise ValueError(f\"Test subject {test_subject} not found in participants.tsv\")\n",
    "    else:\n",
    "        # Randomly select test subjects\n",
    "        num_test_subjects = int(len(participants_df) * test_subject_percentage)\n",
    "        test_subjects = participants_df.sample(n=num_test_subjects, random_state=42)[\"participant_id\"].values\n",
    "        test_subjects_list = list(test_subjects)\n",
    "\n",
    "    train_subjects_list = [sub for sub in participants_df[\"participant_id\"].values if sub not in test_subjects_list]\n",
    "    print(f\"Number of train subjects: {len(train_subjects_list)}\")\n",
    "\n",
    "\n",
    "    test_df = pd.DataFrame()\n",
    "    train_df = pd.DataFrame()\n",
    "\n",
    "    events_files = glob.glob(os.path.join(bids_path, \"**\", \"*_events.tsv\"), recursive=True)\n",
    "    for events_file in events_files:\n",
    "        snirf_file = events_file.replace(bids_path, preprocessed_path).replace(\"_events.tsv\", \"_nirs.nc\")\n",
    "        if not os.path.exists(snirf_file):\n",
    "            print(f\"SNIRF file not found for {snirf_file}. Skipping...\")\n",
    "            continue\n",
    "        # Read the events file\n",
    "        events_df = pd.read_csv(events_file, sep=\"\\t\")\n",
    "        # Get the subject ID from the filename\n",
    "        subject_id = os.path.basename(events_file).split(\"_\")[0]\n",
    "        events_df[\"subject_id\"] = subject_id\n",
    "        events_df = events_df.drop(columns=[\"value\"])\n",
    "        events_df[\"snirf_file\"] = snirf_file\n",
    "        events_df['trial_type'] = events_df['trial_type'].map({\"Left\": 0, \"Right\": 1})\n",
    "        # Check if the subject is in the test list\n",
    "        if subject_id in test_subjects_list:\n",
    "            # Save the test events file\n",
    "            test_df = pd.concat([test_df, events_df])\n",
    "\n",
    "        else:\n",
    "            # Save the train events file\n",
    "            train_df = pd.concat([train_df, events_df])\n",
    "\n",
    "    # Save the test and train DataFrames to CSV files\n",
    "    test_df.to_csv(os.path.join(bids_path, \"test_events.csv\"), index=False)\n",
    "    train_df.to_csv(os.path.join(bids_path, \"train_events.csv\"), index=False)\n",
    "    return os.path.join(bids_path, \"train_events.csv\"), os.path.join(bids_path, \"test_events.csv\")\n",
    "\n",
    "def create_train_test_segments_aug(bids_path, preprocessed_path, test_subjects_list=None, test_subject_percentage=0.2, exclude_subjects=None):\n",
    "    \"\"\"\n",
    "    Create train and test files for the dataset.\n",
    "    \"\"\"\n",
    "    if bids_path is not None:\n",
    "        participants_df = pd.read_csv(os.path.join(bids_path, \"participants.tsv\"), sep=\"\\t\")\n",
    "    else:\n",
    "        participants = glob.glob(preprocessed_path + \"/sub-*\")\n",
    "        participants = [os.path.basename(p) for p in participants]\n",
    "        participants_df = pd.DataFrame({\"participant_id\": participants})\n",
    "\n",
    "    if exclude_subjects is not None:\n",
    "        participants_df = participants_df[~participants_df[\"participant_id\"].isin(exclude_subjects)]\n",
    "        print(f\"Excluding subjects: {exclude_subjects}\")\n",
    "\n",
    "    if test_subjects_list is not None:\n",
    "        for test_subject in test_subjects_list:\n",
    "            if test_subject not in participants_df[\"participant_id\"].values:\n",
    "                raise ValueError(f\"Test subject {test_subject} not found in participants.tsv\")\n",
    "    else:\n",
    "        # Randomly select test subjects\n",
    "        num_test_subjects = int(len(participants_df) * test_subject_percentage)\n",
    "        test_subjects = participants_df.sample(n=num_test_subjects, random_state=42)[\"participant_id\"].values\n",
    "        test_subjects_list = list(test_subjects)\n",
    "\n",
    "    train_subjects_list = [sub for sub in participants_df[\"participant_id\"].values if sub not in test_subjects_list]\n",
    "    print(f\"Number of train subjects: {len(train_subjects_list)}\")\n",
    "\n",
    "\n",
    "    test_df = pd.DataFrame()\n",
    "    train_df = pd.DataFrame()\n",
    "\n",
    "    labels = {\"Left\": 0, \"Right\": 1, \"left\": 0, \"right\": 1}\n",
    "\n",
    "    train_files =  []\n",
    "    for train_subject in train_subjects_list:\n",
    "        train_files += glob.glob(os.path.join(preprocessed_path, train_subject, \"**\", \"*.nc\"))\n",
    "    train_labels = []\n",
    "    for f in train_files:\n",
    "        if os.path.basename(f).endswith(\"_test.nc\"):\n",
    "            train_labels.append(labels[os.path.basename(f).split(\"_\")[-3]])\n",
    "        else:\n",
    "            train_labels.append(labels[os.path.basename(f).split(\"_\")[-2]])\n",
    "    train_df = pd.DataFrame({\n",
    "        \"snirf_file\": train_files,\n",
    "        \"trial_type\": train_labels})\n",
    "    \n",
    "    test_files =  []\n",
    "    for test_subject in test_subjects_list:\n",
    "        test_files += glob.glob(os.path.join(preprocessed_path, test_subject, \"**\", \"*_test.nc\"))\n",
    "    test_labels = []\n",
    "    for f in test_files:\n",
    "        if os.path.basename(f).endswith(\"_test.nc\"):\n",
    "            test_labels.append(labels[os.path.basename(f).split(\"_\")[-3]])\n",
    "        else:\n",
    "            test_labels.append(labels[os.path.basename(f).split(\"_\")[-2]])\n",
    "    test_df = pd.DataFrame({\n",
    "        \"snirf_file\": test_files,\n",
    "        \"trial_type\": test_labels})\n",
    "\n",
    "    # Save the test and train DataFrames to CSV files\n",
    "    test_df.to_csv(os.path.join(preprocessed_path, \"test_segments.csv\"), index=False)\n",
    "    train_df.to_csv(os.path.join(preprocessed_path, \"train_segments.csv\"), index=False)\n",
    "    return os.path.join(preprocessed_path, \"train_segments.csv\"), os.path.join(preprocessed_path, \"test_segments.csv\")\n",
    "\n",
    "def create_train_test_segments(bids_path, preprocessed_path, test_subjects_list=None, test_subject_percentage=0.2, exclude_subjects=None):\n",
    "    \"\"\"\n",
    "    Create train and test files for the dataset.\n",
    "    \"\"\"\n",
    "    # Load the participants.tsv file\n",
    "    if bids_path is not None:\n",
    "        participants_df = pd.read_csv(os.path.join(bids_path, \"participants.tsv\"), sep=\"\\t\")\n",
    "    else:\n",
    "        participants = glob.glob(preprocessed_path + \"/sub-*\")\n",
    "        participants = [os.path.basename(p) for p in participants]\n",
    "        participants_df = pd.DataFrame({\"participant_id\": participants})\n",
    "\n",
    "    if exclude_subjects is not None:\n",
    "        participants_df = participants_df[~participants_df[\"participant_id\"].isin(exclude_subjects)]\n",
    "        print(f\"Excluding subjects: {exclude_subjects}\")\n",
    "\n",
    "    if test_subjects_list is not None:\n",
    "        for test_subject in test_subjects_list:\n",
    "            if test_subject not in participants_df[\"participant_id\"].values:\n",
    "                raise ValueError(f\"Test subject {test_subject} not found in participants.tsv\")\n",
    "    else:\n",
    "        # Randomly select test subjects\n",
    "        num_test_subjects = int(len(participants_df) * test_subject_percentage)\n",
    "        test_subjects = participants_df.sample(n=num_test_subjects, random_state=42)[\"participant_id\"].values\n",
    "        test_subjects_list = list(test_subjects)\n",
    "\n",
    "    train_subjects_list = [sub for sub in participants_df[\"participant_id\"].values if sub not in test_subjects_list]\n",
    "    print(f\"Number of train subjects: {len(train_subjects_list)}\")\n",
    "\n",
    "\n",
    "    test_df = pd.DataFrame()\n",
    "    train_df = pd.DataFrame()\n",
    "\n",
    "    labels = {\"Left\": 1, \"Right\": 0, \"left\": 1, \"right\": 0}\n",
    "\n",
    "    train_files =  []\n",
    "    for train_subject in train_subjects_list:\n",
    "        train_files += glob.glob(os.path.join(preprocessed_path, train_subject, \"**\", \"*.nc\"))\n",
    "    train_labels = []\n",
    "    for f in train_files:\n",
    "        if os.path.basename(f).endswith(\"_test.nc\"):\n",
    "            train_labels.append(labels[os.path.basename(f).split(\"_\")[-3]])\n",
    "        else:\n",
    "            train_labels.append(labels[os.path.basename(f).split(\"_\")[-2]])\n",
    "    train_df = pd.DataFrame({\n",
    "        \"snirf_file\": train_files,\n",
    "        \"trial_type\": train_labels})\n",
    "    \n",
    "    test_files =  []\n",
    "    for test_subject in test_subjects_list:\n",
    "        test_files += glob.glob(os.path.join(preprocessed_path, test_subject, \"**\", \"*_test.nc\"))\n",
    "    test_labels = []\n",
    "    for f in test_files:\n",
    "        if os.path.basename(f).endswith(\"_test.nc\"):\n",
    "            test_labels.append(labels[os.path.basename(f).split(\"_\")[-3]])\n",
    "        else:\n",
    "            test_labels.append(labels[os.path.basename(f).split(\"_\")[-2]])\n",
    "    test_df = pd.DataFrame({\n",
    "        \"snirf_file\": test_files,\n",
    "        \"trial_type\": test_labels})\n",
    "\n",
    "    # Save the test and train DataFrames to CSV files\n",
    "    test_df.to_csv(os.path.join(preprocessed_path, \"test_segments.csv\"), index=False)\n",
    "    train_df.to_csv(os.path.join(preprocessed_path, \"train_segments.csv\"), index=False)\n",
    "    return os.path.join(preprocessed_path, \"train_segments.csv\"), os.path.join(preprocessed_path, \"test_segments.csv\")\n",
    "\n",
    "def create_train_test_segments_grad(bids_path, preprocessed_path, test_subjects_list=None, exclude_subjects=None, train_dataset=None, fmri_percentage=0.2, fmri_subjects=24):\n",
    "    \"\"\"\n",
    "    Create train and test files for the dataset.\n",
    "    \"\"\"\n",
    "    # Load the participants.tsv file\n",
    "    # yuanyuan = [\"sub-170\", \"sub-171\", \"sub-173\", \"sub-174\", \"sub-176\", \"sub-177\", \n",
    "    # \"sub-179\", \"sub-181\", \"sub-182\", \"sub-183\", \"sub-184\", \"sub-185\"]\n",
    "    # laura = [\"sub-547\", \"sub-568\", \"sub-577\", \"sub-580\", \"sub-581\", \"sub-583\", \"sub-586\",\n",
    "    # \"sub-587\", \"sub-588\", \"sub-592\", \"sub-613\", \"sub-618\", \"sub-619\", \"sub-621\", \"sub-633\",\n",
    "    # \"sub-638\", \"sub-639\", \"sub-640\"]\n",
    "    yuanyuan = ['sub-177', 'sub-182', 'sub-185', 'sub-633', 'sub-176', 'sub-580', 'sub-583', 'sub-586', 'sub-618', 'sub-640', 'sub-568', 'sub-621']\n",
    "    laura = ['sub-179', 'sub-183', 'sub-581', 'sub-181', 'sub-587', 'sub-577', 'sub-638', 'sub-619', 'sub-613', 'sub-592', 'sub-170', 'sub-173']\n",
    "\n",
    "    if bids_path is not None:\n",
    "        participants_df = pd.read_csv(os.path.join(bids_path, \"participants.tsv\"), sep=\"\\t\")\n",
    "    else:\n",
    "        participants = glob.glob(preprocessed_path + \"/sub-*\")\n",
    "        participants = [os.path.basename(p) for p in participants]\n",
    "        participants_df = pd.DataFrame({\"participant_id\": participants})\n",
    "\n",
    "    if exclude_subjects is not None:\n",
    "        participants_df = participants_df[~participants_df[\"participant_id\"].isin(exclude_subjects)]\n",
    "        print(f\"Excluding subjects: {exclude_subjects}\")\n",
    "\n",
    "    if test_subjects_list is not None:\n",
    "        for test_subject in test_subjects_list:\n",
    "            if test_subject not in participants_df[\"participant_id\"].values:\n",
    "                raise ValueError(f\"Test subject {test_subject} not found in participants.tsv\")\n",
    "    else:\n",
    "        # Randomly select test subjects\n",
    "        num_test_subjects = int(len(participants_df) * test_subject_percentage)\n",
    "        test_subjects = participants_df.sample(n=num_test_subjects, random_state=42)[\"participant_id\"].values\n",
    "        test_subjects_list = list(test_subjects)\n",
    "\n",
    "    if train_dataset == \"yuanyuan\":\n",
    "        data_list = yuanyuan\n",
    "    elif train_dataset == \"laura\":\n",
    "        data_list = laura + yuanyuan\n",
    "    elif train_dataset == \"fmri\":\n",
    "        data_list = participants_df[\"participant_id\"].values\n",
    "        fmri = [sub for sub in data_list if sub not in laura + yuanyuan]\n",
    "        fmri_data = random.sample(fmri, int(fmri_subjects))\n",
    "        data_list = laura + yuanyuan + fmri_data\n",
    "    else:\n",
    "        data_list = participants_df[\"participant_id\"].values\n",
    "        fmri = [sub for sub in data_list if sub not in yuanyuan]\n",
    "        fmri_data = random.sample(fmri, int(fmri_subjects))\n",
    "        data_list = yuanyuan + fmri_data        \n",
    "\n",
    "    train_subjects_list = [sub for sub in participants_df[\"participant_id\"].values if sub not in test_subjects_list and sub in data_list]\n",
    "    print(f\"Number of train subjects: {len(train_subjects_list)}\")\n",
    "\n",
    "\n",
    "    test_df = pd.DataFrame()\n",
    "    train_df = pd.DataFrame()\n",
    "\n",
    "    labels = {\"Left\": 0, \"Right\": 1, \"left\": 0, \"right\": 1}\n",
    "\n",
    "    train_files =  []\n",
    "    for train_subject in train_subjects_list:\n",
    "        train_files += glob.glob(os.path.join(preprocessed_path, train_subject, \"**\", \"*_test.nc\"))\n",
    "    train_labels = []\n",
    "    for f in train_files:\n",
    "        if os.path.basename(f).endswith(\"_test.nc\"):\n",
    "            train_labels.append(labels[os.path.basename(f).split(\"_\")[-3]])\n",
    "        else:\n",
    "            train_labels.append(labels[os.path.basename(f).split(\"_\")[-2]])\n",
    "    train_df = pd.DataFrame({\n",
    "        \"snirf_file\": train_files,\n",
    "        \"trial_type\": train_labels})\n",
    "    \n",
    "    test_files =  []\n",
    "    for test_subject in test_subjects_list:\n",
    "        test_files += glob.glob(os.path.join(preprocessed_path, test_subject, \"**\", \"*_test.nc\"))\n",
    "    test_labels = []\n",
    "    for f in test_files:\n",
    "        if os.path.basename(f).endswith(\"_test.nc\"):\n",
    "            test_labels.append(labels[os.path.basename(f).split(\"_\")[-3]])\n",
    "        else:\n",
    "            test_labels.append(labels[os.path.basename(f).split(\"_\")[-2]])\n",
    "    test_df = pd.DataFrame({\n",
    "        \"snirf_file\": test_files,\n",
    "        \"trial_type\": test_labels})\n",
    "\n",
    "    # Save the test and train DataFrames to CSV files\n",
    "    test_df.to_csv(os.path.join(preprocessed_path, \"test_segments.csv\"), index=False)\n",
    "    train_df.to_csv(os.path.join(preprocessed_path, \"train_segments.csv\"), index=False)\n",
    "    return os.path.join(preprocessed_path, \"train_segments.csv\"), os.path.join(preprocessed_path, \"test_segments.csv\")\n",
    "\n",
    "\n",
    "def create_train_test_segments_wustl(bids_path, preprocessed_path, test_subjects_list=None, test_subject_percentage=0.2, exclude_subjects=None):\n",
    "    \"\"\"\n",
    "    Create train and test files for the dataset.\n",
    "    \"\"\"\n",
    "    # Load the participants.tsv file\n",
    "    if bids_path is not None:\n",
    "        participants_df = pd.read_csv(os.path.join(bids_path, \"participants.tsv\"), sep=\"\\t\")\n",
    "    else:\n",
    "        participants = glob.glob(preprocessed_path + \"/sub-*\")\n",
    "        participants = [os.path.basename(p) for p in participants]\n",
    "        participants_df = pd.DataFrame({\"participant_id\": participants})\n",
    "\n",
    "    if exclude_subjects is not None:\n",
    "        participants_df = participants_df[~participants_df[\"participant_id\"].isin(exclude_subjects)]\n",
    "        print(f\"Excluding subjects: {exclude_subjects}\")\n",
    "\n",
    "    if test_subjects_list is not None:\n",
    "        for test_subject in test_subjects_list:\n",
    "            if test_subject not in participants_df[\"participant_id\"].values:\n",
    "                raise ValueError(f\"Test subject {test_subject} not found in participants.tsv\")\n",
    "    else:\n",
    "        # Randomly select test subjects\n",
    "        num_test_subjects = int(len(participants_df) * test_subject_percentage)\n",
    "        test_subjects = participants_df.sample(n=num_test_subjects, random_state=42)[\"participant_id\"].values\n",
    "        test_subjects_list = list(test_subjects)\n",
    "\n",
    "    train_subjects_list = [sub for sub in participants_df[\"participant_id\"].values if sub not in test_subjects_list]\n",
    "    print(f\"Number of train subjects: {len(train_subjects_list)}\")\n",
    "\n",
    "\n",
    "    test_df = pd.DataFrame()\n",
    "    train_df = pd.DataFrame()\n",
    "\n",
    "    labels = {\"OV\": 1, \"CV\": 1, \"rest\": 2, \"RW\": 0, \"MEMa1\": 2}\n",
    "\n",
    "    train_files =  []\n",
    "    for train_subject in train_subjects_list:\n",
    "        train_files += glob.glob(os.path.join(preprocessed_path, train_subject, \"**\", \"*_test.nc\"), recursive=True)\n",
    "    train_labels = []\n",
    "    for f in train_files:\n",
    "        if os.path.basename(f).endswith(\"_test.nc\"):\n",
    "            train_labels.append(labels[os.path.basename(f).split(\"_\")[-3]])\n",
    "        else:\n",
    "            train_labels.append(labels[os.path.basename(f).split(\"_\")[-2]])\n",
    "    train_df = pd.DataFrame({\n",
    "        \"snirf_file\": train_files,\n",
    "        \"trial_type\": train_labels})\n",
    "    \n",
    "    test_files =  []\n",
    "    for test_subject in test_subjects_list:\n",
    "        test_files += glob.glob(os.path.join(preprocessed_path, test_subject, \"**\", \"*_test.nc\"), recursive=True)\n",
    "    test_labels = []\n",
    "    for f in test_files:\n",
    "        if os.path.basename(f).endswith(\"_test.nc\"):\n",
    "            test_labels.append(labels[os.path.basename(f).split(\"_\")[-3]])\n",
    "        else:\n",
    "            test_labels.append(labels[os.path.basename(f).split(\"_\")[-2]])\n",
    "    test_df = pd.DataFrame({\n",
    "        \"snirf_file\": test_files,\n",
    "        \"trial_type\": test_labels})\n",
    "\n",
    "    train_df = train_df[train_df['trial_type'] != 2]\n",
    "    test_df = test_df[test_df['trial_type'] != 2]\n",
    "\n",
    "    # Save the test and train DataFrames to CSV files\n",
    "    test_df.to_csv(os.path.join(preprocessed_path, \"test_segments.csv\"), index=False)\n",
    "    train_df.to_csv(os.path.join(preprocessed_path, \"train_segments.csv\"), index=False)\n",
    "    return os.path.join(preprocessed_path, \"train_segments.csv\"), os.path.join(preprocessed_path, \"test_segments.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
