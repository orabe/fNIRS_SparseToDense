{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372b9540",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import cedalion\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from torch.utils.data import Dataset\n",
    "import cedalion.sigproc.motion_correct as motion_correct\n",
    "\n",
    "\n",
    "class PreprocessedNIRSDataset(Dataset):\n",
    "    def __init__(self, data_csv_path, mode=\"train\"):\n",
    "        self.data_csv = pd.read_csv(data_csv_path)\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_csv)  # Total number of trials\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Loads a single trial on demand (efficient memory usage).\n",
    "        \"\"\"\n",
    "        data_row = self.data_csv.loc[idx]\n",
    "\n",
    "        record = xr.open_dataarray(data_row[\"snirf_file\"])\n",
    "        record.time.attrs['units'] = 'seconds'\n",
    "        duration = 7\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "            random_delta = np.random.choice(np.linspace(-1, 1, 5))\n",
    "            start_time = data_row[\"onset\"] + random_delta  # in seconds\n",
    "        else:\n",
    "            start_time = data_row[\"onset\"]\n",
    "        end_time = data_row[\"onset\"] + duration  + 5   # in seconds\n",
    "\n",
    "        baseline = record.sel(time=slice(data_row[\"onset\"] - 2.5 , data_row[\"onset\"])).mean(\"time\")\n",
    "\n",
    "        # Then, trimming is easy with `.sel()`:\n",
    "        x = x.sel(time=slice(start_time, end_time)) - baseline\n",
    "        x = x.isel(time=slice(0, 61))\n",
    "\n",
    "\n",
    "        x = x + np.abs(x.min()) + 10\n",
    "        hbr = 1/x\n",
    "        hbr_baseline = hbr.mean(\"time\")\n",
    "        x = ((hbr - hbr_baseline)/hbr_baseline)\n",
    "\n",
    "        # Normalize\n",
    "        x = x / np.abs(x).max()\n",
    "        x = x.fillna(0)\n",
    "        \n",
    "        y = data_row[\"trial_type\"]\n",
    "\n",
    "        # Convert to tensor\n",
    "        trial_tensor = torch.tensor(x.values, dtype=torch.float32).unsqueeze(1)\n",
    "        label_tensor = torch.tensor(int(y), dtype=torch.long)\n",
    "\n",
    "        return trial_tensor, label_tensor\n",
    "    \n",
    "class PreprocessedNIRSDatasetV2(Dataset):\n",
    "    def __init__(self, data_csv_path, mode=\"train\"):\n",
    "        self.data_csv = pd.read_csv(data_csv_path)\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_csv)  # Total number of trials\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Loads a single trial on demand (efficient memory usage).\n",
    "        \"\"\"\n",
    "        data_row = self.data_csv.loc[idx]\n",
    "\n",
    "        record = xr.open_dataarray(data_row[\"snirf_file\"])\n",
    "        record.time.attrs['units'] = 'seconds'\n",
    "\n",
    "        record = record / np.abs(record).max()\n",
    "        record = record.fillna(0)\n",
    "\n",
    "        duration = 7\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "            random_delta = np.random.choice(np.linspace(-1, 1, 5))\n",
    "            start_time = data_row[\"onset\"] + random_delta  # in seconds\n",
    "        else:\n",
    "            start_time = data_row[\"onset\"]\n",
    "        end_time = data_row[\"onset\"] + duration + 5   # in seconds\n",
    "\n",
    "        baseline = record.sel(time=slice(data_row[\"onset\"] - 2.5 , data_row[\"onset\"])).mean(\"time\")\n",
    "\n",
    "        # Then, trimming is easy with `.sel()`:\n",
    "        x = record.sel(time=slice(start_time, end_time)) - baseline\n",
    "        x = x.isel(time=slice(0, 61))\n",
    "\n",
    "        # Normalize        \n",
    "        y = data_row[\"trial_type\"]\n",
    "\n",
    "        # Convert to tensor\n",
    "        trial_tensor = torch.tensor(x.values, dtype=torch.float32)\n",
    "        label_tensor = torch.tensor(int(y), dtype=torch.long)\n",
    "\n",
    "        return trial_tensor, label_tensor\n",
    "    \n",
    "class PreprocessedNIRSDatasetV3(Dataset):\n",
    "    def __init__(self, data_csv_path, mode=\"train\"):\n",
    "        self.data_csv = pd.read_csv(data_csv_path)\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_csv)  # Total number of trials\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Loads a single trial on demand (efficient memory usage).\n",
    "        \"\"\"\n",
    "        data_row = self.data_csv.loc[idx]\n",
    "\n",
    "        record = xr.open_dataarray(data_row[\"snirf_file\"])\n",
    "        record.time.attrs['units'] = 'seconds'\n",
    "        duration = 7\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "            random_delta = np.random.choice(np.linspace(-1, 1, 5))\n",
    "            start_time = data_row[\"onset\"] + random_delta  # in seconds\n",
    "        else:\n",
    "            start_time = data_row[\"onset\"]\n",
    "        end_time = data_row[\"onset\"] + duration + 5   # in seconds\n",
    "\n",
    "        baseline = record.sel(time=slice(data_row[\"onset\"] - 2.5 , data_row[\"onset\"])).mean(\"time\")\n",
    "\n",
    "        # Then, trimming is easy with `.sel()`:\n",
    "        x = record.sel(time=slice(start_time, end_time)) - baseline\n",
    "        x = x.isel(time=slice(0, 61))\n",
    "\n",
    "        # Normalize\n",
    "        x = x / np.abs(x).max()\n",
    "        x = x.fillna(0)\n",
    "        \n",
    "        y = data_row[\"trial_type\"]\n",
    "\n",
    "        # Convert to tensor\n",
    "        trial_tensor = torch.tensor(x.values, dtype=torch.float32).unsqueeze(1)\n",
    "        label_tensor = torch.tensor(int(y), dtype=torch.long)\n",
    "\n",
    "        return trial_tensor, label_tensor\n",
    "\n",
    "class fNIRSChannelSpaceLoad(Dataset):\n",
    "    def __init__(self, data_csv_path, mode=\"train\", chromo=\"HbO\"):\n",
    "        self.data_csv = pd.read_csv(data_csv_path)\n",
    "        self.mode = mode\n",
    "        self.chromo = chromo\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_csv)  # Total number of trials\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Loads a single trial on demand (efficient memory usage).\n",
    "        \"\"\"\n",
    "        data_row = self.data_csv.loc[idx]\n",
    "        if self.chromo == \"both\":\n",
    "            record = xr.open_dataarray(data_row[\"snirf_file\"])\n",
    "        else:\n",
    "            record = xr.open_dataarray(data_row[\"snirf_file\"]).sel(chromo=self.chromo)\n",
    "        record.time.attrs['units'] = 'seconds'\n",
    "\n",
    "        duration = 10\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "            random_delta = np.random.choice(np.linspace(-2.5, 2.5, 9))\n",
    "            start_time = data_row[\"onset\"] + random_delta  # in seconds\n",
    "        else:\n",
    "            start_time = data_row[\"onset\"]\n",
    "        end_time = data_row[\"onset\"] + duration + 5   # in seconds\n",
    "\n",
    "        baseline = record.sel(time=slice(data_row[\"onset\"] - 2.5 , data_row[\"onset\"])).mean(\"time\")\n",
    "\n",
    "        # Then, trimming is easy with `.sel()`:\n",
    "        x = record.sel(time=slice(start_time, end_time)) - baseline\n",
    "        x = x.isel(time=slice(0, 87))\n",
    "\n",
    "        # Normalize        \n",
    "        y = data_row[\"trial_type\"]\n",
    "\n",
    "        # Convert to tensor\n",
    "        if self.chromo == 'both':\n",
    "            trial_tensor = torch.tensor(x.values, dtype=torch.float32)\n",
    "        else:\n",
    "            trial_tensor = torch.tensor(x.values, dtype=torch.float32).unsqueeze(1)\n",
    "        label_tensor = torch.tensor(int(y), dtype=torch.long)\n",
    "\n",
    "        return trial_tensor, label_tensor\n",
    "\n",
    "class fNIRSChannelSpaceSegmentLoad(Dataset):\n",
    "    def __init__(self, data_csv_path, mode=\"train\", chromo=\"HbO\"):\n",
    "        self.data_csv = pd.read_csv(data_csv_path)\n",
    "        self.mode = mode\n",
    "        self.chromo = chromo\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_csv)  # Total number of trials\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Loads a single trial on demand (efficient memory usage).\n",
    "        \"\"\"\n",
    "        data_row = self.data_csv.loc[idx]\n",
    "        if self.chromo == \"both\":\n",
    "            record = xr.open_dataarray(data_row[\"snirf_file\"])\n",
    "        else:\n",
    "            record = xr.open_dataarray(data_row[\"snirf_file\"]).sel(chromo=self.chromo)\n",
    "        record.time.attrs['units'] = 'seconds'\n",
    "\n",
    "        x = record\n",
    "        # Normalize        \n",
    "        y = data_row[\"trial_type\"]\n",
    "\n",
    "        # Convert to tensor\n",
    "        if self.chromo == 'both':\n",
    "            trial_tensor = torch.tensor(x.values, dtype=torch.float32)\n",
    "        else:\n",
    "            trial_tensor = torch.tensor(x.values, dtype=torch.float32).unsqueeze(1)\n",
    "        label_tensor = torch.tensor(int(y), dtype=torch.long)\n",
    "\n",
    "        return trial_tensor, label_tensor\n",
    "\n",
    "\n",
    "\n",
    "class fNIRSPreloadDataset(Dataset):\n",
    "    def __init__(self, data_csv_path, mode=\"train\", chromo=\"HbO\"):\n",
    "        self.data_csv = pd.read_csv(data_csv_path)\n",
    "        self.mode = mode\n",
    "        self.chromo = chromo\n",
    "\n",
    "        # === Pre-load all trials into RAM ===\n",
    "        self.all_trials = []\n",
    "        self.all_labels = []\n",
    "\n",
    "        print(f\"Preloading {len(self.data_csv)} trials into memory...\")\n",
    "\n",
    "        for i, row in self.data_csv.iterrows():\n",
    "            if chromo == \"both\":\n",
    "                record = xr.open_dataarray(row[\"snirf_file\"])\n",
    "                trial_tensor = torch.tensor(record.values, dtype=torch.float32)\n",
    "            else:\n",
    "                try:\n",
    "                    record = xr.open_dataarray(row[\"snirf_file\"]).sel(chromo=chromo)\n",
    "                    current_len = record.shape[1]\n",
    "                    target_len = 87\n",
    "\n",
    "                    # only pad if shorter than target\n",
    "                    if current_len < target_len:\n",
    "                        print(\"Padding trial from length\", current_len, \"to\", target_len)\n",
    "                        pad_width = [(0, 0), (0, target_len - current_len)]\n",
    "                        record = xr.DataArray(\n",
    "                            np.pad(record.values, pad_width, mode='constant', constant_values=0),\n",
    "                            dims=record.dims,\n",
    "                            coords={\n",
    "                                record.dims[0]: record.coords[record.dims[0]].values,\n",
    "                                record.dims[1]: np.arange(target_len)\n",
    "                            }\n",
    "                        )\n",
    "                    trial_tensor = torch.tensor(record.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {row['snirf_file']}: {e}\")\n",
    "                    continue\n",
    "            label_tensor = torch.tensor(int(row[\"trial_type\"]), dtype=torch.long)\n",
    "\n",
    "            self.all_trials.append(trial_tensor)\n",
    "            self.all_labels.append(label_tensor)\n",
    "\n",
    "        print(f\"Loaded {len(self.all_trials)} trials into memory.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_trials)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.all_trials[idx], self.all_labels[idx]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
